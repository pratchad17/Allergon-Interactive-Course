{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqfK-B4Ji42K"
      },
      "source": [
        "# Data Science Project Based on Australian Vehicle Prices Dataset\n",
        "\n",
        "Jane Citizen 40987654\n",
        "\n",
        "## Dataset Description:\n",
        "\n",
        "This dataset contains the latest information on car prices in Australia for the year 2023. It covers various brands, models, types, and features of cars sold in the Australian market. It provides useful insights into the trends and factors influencing the car prices in Australia. The dataset includes information such as brand, year, model, car/suv, title, used/new, transmission, engine, drive type, fuel type, fuel consumption, kilometres, colour (exterior/interior), location, cylinders in engine, body type, doors, seats, and price. The dataset has over 16,000 records of car listings from various online platforms in Australia.\n",
        "\n",
        "* Brand: Name of the car manufacturer\n",
        "* Year: Year of manufacture or release\n",
        "* Model: Name or code of the car model\n",
        "* Car/Suv: Type of the car (car or suv)\n",
        "* Title: Title or description of the car\n",
        "* UsedOrNew: Condition of the car (used or new)\n",
        "* Transmission: Type of transmission (manual or automatic)\n",
        "* Engine: Engine capacity or power (in litres or kilowatts)\n",
        "* DriveType: Type of drive (front-wheel, rear-wheel, or all-wheel)\n",
        "* FuelType: Type of fuel (petrol, diesel, hybrid, or electric)\n",
        "* FuelConsumption: Fuel consumption rate (in litres per 100 km)\n",
        "* Kilometres: Distance travelled by the car (in kilometres)\n",
        "* ColourExtInt: Colour of the car (exterior and interior)\n",
        "* Location: Location of the car (city and state)\n",
        "* CylindersinEngine: Number of cylinders in the engine\n",
        "* B odyType: Shape or style of the car body (sedan, hatchback, coupe, etc.)\n",
        "* Doors: Number of doors in the car\n",
        "* Seats: Number of seats in the car\n",
        "* Price: Price of the car (in Australian dollars)\n",
        "\n",
        "\n",
        "## AIM:\n",
        "\n",
        "We would like to predict the price of the car base on the cars' features (e.g. manufacture year, transmission, engine). Meanwhile, we we like to compare the performance of different regresion models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrxD3Dzai42L"
      },
      "source": [
        "## Import Libraries\n",
        "\n",
        "Here we import all the libraries we need."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import linear_model\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Random seed for reproducibility\n",
        "student_id = 48726591\n",
        "\n",
        "# Data Loading\n",
        "file_csv = \"australian_vehicle_prices.csv\"\n",
        "data = pd.read_csv(file_csv)\n",
        "\n",
        "# Data Cleaning and Missing Value Imputation\n",
        "data.replace(['-', 'POA'], np.nan, inplace=True)\n",
        "data['Location'] = data['Location'].str.replace('AU-VIC', 'VIC')\n",
        "\n",
        "# Impute numerical columns\n",
        "numerical_imputer = SimpleImputer(strategy='mean')\n",
        "numerical_columns = ['FuelConsumption', 'Kilometres', 'CylindersinEngine', 'Doors', 'Seats', 'Displacement']\n",
        "\n",
        "\n",
        "# Impute categorical columns\n",
        "data[['Transmission', 'DriveType', 'FuelType', 'Location']] = data[['Transmission', 'DriveType', 'FuelType', 'Location']].fillna('unknown')\n",
        "\n",
        "# Encode categorical variables\n",
        "categorical_features = ['Transmission', 'DriveType', 'FuelType', 'Location']\n",
        "encoder = OrdinalEncoder()\n",
        "data[categorical_features] = encoder.fit_transform(data[categorical_features])\n",
        "\n",
        "# Feature Selection and Data Splitting\n",
        "features = ['Year', 'Transmission', 'DriveType', 'FuelConsumption', 'Kilometres', 'CylindersinEngine', 'Doors', 'Seats', 'Displacement']\n",
        "\n",
        "y = data['Price']\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.preprocessing import OrdinalEncoder, SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import linear_model\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Random seed for reproducibility\n",
        "student_id = 48726591\n",
        "\n",
        "# Data Loading\n",
        "file_csv = \"australian_vehicle_prices.csv\"\n",
        "data = pd.read_csv(file_csv)\n",
        "\n",
        "# Data Cleaning and Missing Value Imputation\n",
        "data.replace(['-', 'POA'], np.nan, inplace=True)\n",
        "data['Location'] = data['Location'].str.replace('AU-VIC', 'VIC')\n",
        "\n",
        "# Impute numerical columns\n",
        "numerical_imputer = SimpleImputer(strategy='mean')\n",
        "numerical_columns = ['FuelConsumption', 'Kilometres', 'CylindersinEngine', 'Doors', 'Seats', 'Displacement']\n",
        "data[numerical_columns] = numerical_imputer.fit_transform(data[numerical_columns])\n",
        "\n",
        "# Impute categorical columns\n",
        "data[['Transmission', 'DriveType', 'FuelType', 'Location']] = data[['Transmission', 'DriveType', 'FuelType', 'Location']].fillna('unknown')\n",
        "\n",
        "# Encode categorical variables\n",
        "categorical_features = ['Transmission', 'DriveType', 'FuelType', 'Location']\n",
        "encoder = OrdinalEncoder()\n",
        "data[categorical_features] = encoder.fit_transform(data[categorical_features])\n",
        "\n",
        "# Feature Selection and Data Splitting\n",
        "features = ['Year', 'Transmission', 'DriveType', 'FuelConsumption', 'Kilometres', 'CylindersinEngine', 'Doors', 'Seats', 'Displacement']\n",
        "X = data[features]\n",
        "y = data['Price']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=student_id)\n",
        "\n",
        "# Model Training and Evaluation\n",
        "def evaluate_model(y_true, y_pred, model_name):\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "    print(f\"{model_name} Performance:\")\n",
        "    print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
        "    print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
        "    print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
        "    print(f\"R-squared (R²): {r2:.2f}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "# Initialize and evaluate models\n",
        "models = {\n",
        "    \"Linear Regression\": linear_model.LinearRegression(),\n",
        "    \"Decision Tree Regressor\": DecisionTreeRegressor(random_state=student_id),\n",
        "    \"MLP Regressor\": MLPRegressor(max_iter=500, random_state=student_id)\n",
        "}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    evaluate_model(y_test, y_pred, model_name)\n",
        "\n",
        "\n",
        "# Model Training and Evaluation\n",
        "def evaluate_model(y_true, y_pred, model_name):\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "    print(f\"{model_name} Performance:\")\n",
        "    print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
        "    print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
        "    print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
        "    print(f\"R-squared (R²): {r2:.2f}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "# Initialize and evaluate models\n",
        "models = {\n",
        "    \"Linear Regression\": linear_model.LinearRegression(),\n",
        "    \"Decision Tree Regressor\": DecisionTreeRegressor(random_state=student_id),\n",
        "    \"MLP Regressor\": MLPRegressor(max_iter=500, random_state=student_id)\n",
        "}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    evaluate_model(y_test, y_pred, model_name)\n"
      ],
      "metadata": {
        "id": "RmIjMdGuZKHj",
        "outputId": "a5dbed9e-e5b2-4f62-aa9d-3ced3d4b1296",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Found input variables with inconsistent numbers of samples: [14197, 16734]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-c10b572176d1>\u001b[0m in \u001b[0;36m<cell line: 44>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstudent_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m# Model Training and Evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m                     )\n\u001b[1;32m    212\u001b[0m                 ):\n\u001b[0;32m--> 213\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2780\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"At least one array required as input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2782\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2784\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [14197, 16734]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the performance of training set and testing set are similar, we can say it is not overfitting."
      ],
      "metadata": {
        "id": "ymevFNcGwsnE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysis\n",
        "\n",
        "According to the result we have, among these three models (LR, DTR and MLP) the best option for this dataset is DTR. However, the releationships among the features within this dataset are not obvious for these models to catch, thus all the performance are not very satisfying. We might need to further clean the data (*e.g.* remove outliers) or deploy deep learning models for the prediction."
      ],
      "metadata": {
        "id": "y8N53T9rxeX_"
      }
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "a89ca70b77bf3904d6e71dcc50960c234158b7102660c3bbb1422648282c4bd9"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}